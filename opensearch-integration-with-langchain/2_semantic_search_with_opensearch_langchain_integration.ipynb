{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc7911e",
   "metadata": {},
   "source": [
    "OCI OpenSearch Service sample notebook.\n",
    "\n",
    "Copyright (c) 2024 Oracle, Inc. All rights reserved. Licensed under the [Universal Permissive License (UPL) v 1.0](https://oss.oracle.com/licenses/upl/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308503e-6459-4ce5-8041-031a372dc1e3",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf0003-ded7-4529-a7f4-57860213939e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prereqs: Install/Upgrade Langchain along with other necesaries libraries \n",
    "you can use **`pip`** to  install all the required dependencies into your conda or python. Recommended packages include:\n",
    "- **langchain**: This will give you environment access to all the native langchain libraries \n",
    "- **langchain-community**: this install extended libraries/integration from communities\n",
    "- **oracle_ads**: this is the Oracle Data Science sdk that allows you to use Oracle Data Science librairies\n",
    "- **oci** : oci sdk\n",
    "- **sentence-transformers**: give you the ability to download sentence-transformers \n",
    "- **opensearch-py** : installs the sdk which allows you access opensearch clusters securely and perform operations\n",
    "- **pypdf**: lanchain pdf processing library\n",
    "- **langchain-huggingface** : with this you can directly register any hugging-face model via langchain integration by specifying the name. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88af566-88da-4b07-94b4-2cbab3a60698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (0.3.9)\n",
      "Requirement already satisfied: langchain-community in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (0.3.9)\n",
      "Requirement already satisfied: opensearch-py in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: pypdf in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (5.1.0)\n",
      "Requirement already satisfied: sentence-transformers in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (3.3.1)\n",
      "Requirement already satisfied: oci in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (2.139.0)\n",
      "Requirement already satisfied: langchain-huggingface in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: oracle_ads in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (2.12.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain) (3.11.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain) (0.3.21)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain) (0.1.143)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: urllib3!=2.2.0,!=2.2.1,<3,>=1.26.19 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from opensearch-py) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from opensearch-py) (2.9.0)\n",
      "Requirement already satisfied: certifi>=2024.07.04 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from opensearch-py) (2024.7.4)\n",
      "Requirement already satisfied: Events in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from opensearch-py) (0.5)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from pypdf) (4.12.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from sentence-transformers) (4.67.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from sentence-transformers) (0.26.3)\n",
      "Requirement already satisfied: Pillow in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: cryptography<46.0.0,>=3.2.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oci) (42.0.8)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=17.5.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oci) (24.2.1)\n",
      "Requirement already satisfied: pytz>=2016.10 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oci) (2024.1)\n",
      "Requirement already satisfied: circuitbreaker<3.0.0,>=1.3.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oci) (1.4.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain-huggingface) (0.20.3)\n",
      "Requirement already satisfied: asteval>=0.9.25 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (1.0.5)\n",
      "Requirement already satisfied: cerberus>=1.3.4 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (1.3.5)\n",
      "Requirement already satisfied: cloudpickle>=1.6.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (3.1.0)\n",
      "Requirement already satisfied: fsspec>=0.8.7 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (2024.10.0)\n",
      "Requirement already satisfied: gitpython>=3.1.2 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (3.1.43)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (3.1.4)\n",
      "Requirement already satisfied: matplotlib<=3.8.4,>=3.1.3 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (3.8.4)\n",
      "Requirement already satisfied: ocifs>=1.1.3 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (1.3.1)\n",
      "Requirement already satisfied: pandas>=2.2.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (2.2.3)\n",
      "Requirement already satisfied: psutil>=5.7.2 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (6.0.0)\n",
      "Requirement already satisfied: python_jsonschema_objects>=0.3.13 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (0.5.7)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from oracle_ads) (0.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
      "Requirement already satisfied: cffi>=1.12 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from cryptography<46.0.0,>=3.2.1->oci) (1.17.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from gitpython>=3.1.2->oracle_ads) (4.0.11)\n",
      "Requirement already satisfied: filelock in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from jinja2>=2.11.2->oracle_ads) (2.1.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle_ads) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle_ads) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle_ads) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle_ads) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle_ads) (3.2.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from pandas>=2.2.0->oracle_ads) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from python-dateutil->opensearch-py) (1.16.0)\n",
      "Requirement already satisfied: inflection>=0.2 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from python_jsonschema_objects>=0.3.13->oracle_ads) (0.5.1)\n",
      "Requirement already satisfied: Markdown>=2.4 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from python_jsonschema_objects>=0.3.13->oracle_ads) (3.7)\n",
      "Requirement already satisfied: jsonschema>=4.18 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from python_jsonschema_objects>=0.3.13->oracle_ads) (4.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: pycparser in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from cffi>=1.12->cryptography<46.0.0,>=3.2.1->oci) (2.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.2->oracle_ads) (5.0.1)\n",
      "Requirement already satisfied: anyio in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from jsonschema>=4.18->python_jsonschema_objects>=0.3.13->oracle_ads) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from jsonschema>=4.18->python_jsonschema_objects>=0.3.13->oracle_ads) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from jsonschema>=4.18->python_jsonschema_objects>=0.3.13->oracle_ads) (0.20.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./conda/python_p310_any_x86_64_v1/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community opensearch-py pypdf  sentence-transformers oci  langchain-huggingface oracle_ads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81546650-6864-46f9-af71-5eff89e63174",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configure necessary variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2478cd2-dee9-4b32-8624-5bff37cfb56f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put your compartment id\n",
    "compartment_id = \"<YOUR-COMPARTMENT-OCID>\"\n",
    "# opensearch_url\n",
    "opensearch_url=\"<YOUR-OPENSEARCH-URL>:9200\"\n",
    "\n",
    "username=\"<YOUR-OPENSEARCH-USERNAME>\"\n",
    "password=\"<YOUR-OPENSEARCH-PWD>\"\n",
    "index_name = \"<YOUR-INDEX-NAME>\"\n",
    "\n",
    "AUTH_TYPE=\"RESOURCE_PRINCIPAL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910260c4-6783-4837-aee8-3259c42d286e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# configure embedding model using LangChain hugging Face integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ef74c9-7348-4a51-b268-1d0d92347469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import the Langchain huggingface library \n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "#select embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d5230-8606-41fe-a9ef-b6d90848f7a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Connection to OpenSearch DB using LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3564db6-40aa-4772-a2dd-48d6e879cdec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import the LangChain Library\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "import oci\n",
    "\n",
    "# Setup Resource Principal for authentication\n",
    "auth_provider = oci.auth.signers.get_resource_principals_signer()\n",
    "auth = (username, password)\n",
    "\n",
    "# Initialize OpenSearch as the vector database\n",
    "vector_db = OpenSearchVectorSearch(opensearch_url=opensearch_url, \n",
    "                            index_name=index_name, \n",
    "                            embedding_function=embedding_model,\n",
    "                            signer=auth_provider,\n",
    "                            auth_type=AUTH_TYPE,\n",
    "                            http_auth=auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914ffdf3-64a0-40c0-ba60-8f3a6bb19001",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load, Preprocess, and Chunk Documents (In this case PDF) with LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0fe9d4c-8d4f-4847-ae06-53fe9feebb7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "def load_and_split_pdfs_with_chunks(directory_path, chunk_size=500, chunk_overlap=50):\n",
    "    \"\"\"\n",
    "    Loads, splits, and further splits PDF documents into overlapping chunks.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing PDF files.\n",
    "        chunk_size (int): Maximum size of each text chunk.\n",
    "        chunk_overlap (int): Overlap size between consecutive chunks.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of text chunks from all the PDFs.\n",
    "    \"\"\"\n",
    "    pdf_documents = []\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        raise FileNotFoundError(f\"Directory '{directory_path}' does not exist.\")\n",
    "    \n",
    "    # List all files in the directory\n",
    "    files = [f for f in os.listdir(directory_path) if f.endswith('.pdf')]\n",
    "    print(f\"Number of pdf documents to process {len(files)}\")\n",
    "    \n",
    "    if not files:\n",
    "        print(\"No PDF files found in the directory.\")\n",
    "        return pdf_documents\n",
    "    \n",
    "    # Load and split each PDF file\n",
    "    for file in tqdm(files, desc=\"Processing PDFs\"):\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        try:\n",
    "            # Load and split the PDF using PyPDFLoader\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            raw_documents = loader.load_and_split()\n",
    "            print(f\"Number of pages in pdf document {file_path} :  {len(raw_documents)}\")\n",
    "            prev_chunks_count=len(pdf_documents)\n",
    "            \n",
    "            # Further split the documents into overlapping chunks\n",
    "            for doc in raw_documents:\n",
    "                pdf_documents.extend(text_splitter.split_text(doc.page_content))\n",
    "            print(f\"Number of chunks processed for pdf document {file_path} :  {len(pdf_documents)- prev_chunks_count}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{file}': {e}\")\n",
    "        \n",
    "\n",
    "    \n",
    "    print(f\"\")\n",
    "    print(f\"Successfully Processed :  {len(files)} Documents/files, split into a total of {len(pdf_documents)} overlaping Chunks.\")\n",
    "    return pdf_documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a58f1c-ea85-49ff-8621-e72d9ab02f62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pdf documents to process 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  40%|████      | 2/5 [00:00<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages in pdf document ./data/pdf/evolution_of_ai_ml.pdf :  93\n",
      "Number of chunks processed for pdf document ./data/pdf/evolution_of_ai_ml.pdf :  281\n",
      "Number of pages in pdf document ./data/pdf/stock_market_today_america_long.pdf :  80\n",
      "Number of chunks processed for pdf document ./data/pdf/stock_market_today_america_long.pdf :  238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  60%|██████    | 3/5 [00:00<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages in pdf document ./data/pdf/covid_pandemic_literature.pdf :  253\n",
      "Number of chunks processed for pdf document ./data/pdf/covid_pandemic_literature.pdf :  758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|██████████| 5/5 [00:01<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages in pdf document ./data/pdf/famous_painters_and_artists.pdf :  225\n",
      "Number of chunks processed for pdf document ./data/pdf/famous_painters_and_artists.pdf :  690\n",
      "Number of pages in pdf document ./data/pdf/stock_market_today_america.pdf :  4\n",
      "Number of chunks processed for pdf document ./data/pdf/stock_market_today_america.pdf :  4\n",
      "\n",
      "Successfully Processed :  5 Documents/files, split into a total of 1971 overlaping Chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_data_path = \"./data/pdf\"\n",
    "chunk_size = 500\n",
    "chunk_overlap = 50\n",
    "processed_pdf_document_chunks = load_and_split_pdfs_with_chunks(directory_path=pdf_data_path, chunk_size=chunk_size, chunk_overlap=chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "601c200c-d4c6-4a71-80aa-afa0b9338c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chunk 0: \n",
      " Stock Market Update in America\n",
      "The evolution of Artificial Intelligence (AI) and Machine Learning (ML) has been a fascinating\n",
      "journey, \n",
      "marked by breakthroughs, setbacks, and transformative discoveries. The story of AI/ML begins in\n",
      "the mid-20th century, \n",
      "when pioneering researchers began to explore the idea of machines that could simulate human\n",
      "intelligence.\n",
      "The 1950s and 1960s are often regarded as the \"classical era\" of AI. During this time, computer\n",
      "scientists like \n",
      "\n",
      " Chunk 1: \n",
      " scientists like \n",
      "Alan Turing, John McCarthy, and Marvin Minsky laid the theoretical foundations of AI. Turing's\n",
      "seminal work, \n",
      "the \"Turing Test,\" proposed a framework to assess whether a machine could exhibit intelligent\n",
      "behavior indistinguishable \n",
      "from that of a human. In 1956, the Dartmouth Conference, organized by McCarthy and others,\n",
      "officially coined the term \n",
      "\"Artificial Intelligence\" and set the stage for decades of research. \n",
      "\n",
      " Chunk 2: \n",
      " In the early years, AI research was dominated by symbolic AI or \"good old-fashioned AI\" (GOFAI).\n",
      "Researchers focused \n",
      "on rule-based systems and symbolic reasoning, which led to the development of early programs like\n",
      "ELIZA, a natural \n",
      "language processing program, and the General Problem Solver. These systems, while\n",
      "groundbreaking, were limited in \n",
      "Page 1 \n",
      "\n",
      " Chunk 3: \n",
      " Stock Market Update in America\n",
      "their ability to handle complexity and ambiguity.\n",
      "The 1970s and 1980s brought about the first \"AI winter,\" a period characterized by reduced funding\n",
      "and enthusiasm for \n",
      "AI research. The limitations of symbolic AI became apparent as researchers struggled to scale these\n",
      "systems to handle \n",
      "real-world problems. During this time, expert systems, which encoded domain-specific knowledge,\n",
      "gained traction but \n",
      "eventually faced scalability issues. \n",
      "\n",
      " Chunk 4: \n",
      " eventually faced scalability issues.\n",
      "The 1990s marked a revival in AI/ML, driven by advancements in computing power and data\n",
      "availability. The rise of \n",
      "statistical methods, particularly in machine learning, shifted the focus from rule-based systems to\n",
      "data-driven approaches. \n",
      "Decision trees, support vector machines, and Bayesian networks became popular tools for tackling\n",
      "classification and \n",
      "prediction problems. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print the first few  documents chunks processed ans ready to be ingested \n",
    "for i in range(5):\n",
    "    print(f\" Chunk {i}: \\n {processed_pdf_document_chunks[i]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63be85-db93-4d65-8ef6-dddfa71f51a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ingest Documents into OpenSearch Vector DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7fcd17d-97ea-4755-bdf2-5afe21fd9bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def ingest_documents_with_embeddings(document_chunks, index_name, vector_db, batch_size=100):\n",
    "    \"\"\"\n",
    "    Ingest Pre-processed Data chunks into a new or existing index along with the auto generated embeddings into Opensearch. i\n",
    "    use bulk ingestion to speedup.\n",
    "    \n",
    "    Args:\n",
    "        pages (list): List of documents to be embedded and stored.\n",
    "        my_index_name (str): Name of the OpenSearch index.\n",
    "        db (OpenSearchVectorSearch): LangChain OpenSearch database instance.\n",
    "\n",
    "        batch_size (int): Maximum number of documents to process in a single batch (default: 95).\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    print(f\"Index Name: {index_name}\")\n",
    "    \n",
    "    # Ingest documents in batches\n",
    "    for i in tqdm(range(0, len(document_chunks), batch_size), desc=\"Ingesting batches\"):\n",
    "        batch = document_chunks[i:i + batch_size]\n",
    "        try:\n",
    "            # vector_db.add_texts(batch)\n",
    "            # vector_db.add_documents(batch)\n",
    "            vector_db.add_texts(texts=batch, \n",
    "                     bulk_size=batch_size,\n",
    "                     embedding=embedding_model, \n",
    "                     opensearch_url=opensearch_url, \n",
    "                     index_name=index_name,\n",
    "                     http_auth=auth)\n",
    "        except Exception as e:\n",
    "            print(f\"Error while adding texts to the opensearch {index_name} index. Error occured in chunks batch {i + 1}-{i+batch_size}: {e}\")\n",
    "    \n",
    "    #refresh index\n",
    "    vector_db.client.indices.refresh(index=index_name)\n",
    "    print(f\"Index '{index_name}' refreshed!\")\n",
    "    print(f\"Successfully ingested {len(document_chunks)} documents into the OpenSearch index '{index_name}'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01877d3c-64b1-467f-b9db-4f766b6dddb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471991ab-ada9-483d-ad3c-0c2939e23550",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: pdf-materials-demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ingesting batches: 100%|██████████| 20/20 [00:40<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'pdf-materials-demo' refreshed!\n",
      "Successfully ingested 1971 documents into the OpenSearch index 'pdf-materials-demo'!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " # Ingest the documents and generate embeddings\n",
    "ingestion_batch_size=100\n",
    "ingest_documents_with_embeddings(document_chunks=processed_pdf_document_chunks, index_name=index_name, vector_db=vector_db, batch_size=ingestion_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b3969-a20f-4a5a-b09d-3e06fda3c6fe",
   "metadata": {},
   "source": [
    "## &nbsp;&nbsp;&nbsp;&nbsp;  Validate that index has been created and validate index mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad0ede4c-405d-4586-a5bf-7161ef92cfca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Mapping: {'pdf-materials-demo': {'mappings': {'properties': {'metadata': {'type': 'object'}, 'text': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'vector_field': {'type': 'knn_vector', 'dimension': 384, 'method': {'engine': 'nmslib', 'space_type': 'l2', 'name': 'hnsw', 'parameters': {'ef_construction': 512, 'm': 16}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "# Check the index mapping\n",
    "response = vector_db.client.indices.get_mapping(index=index_name)\n",
    "print(\"Index Mapping:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de5bbd-03c5-42dd-a233-1f80b9c3363d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "356ba1be-3aa2-4fde-ac0b-fea0a6ccb0bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 7: Perform Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afbca259-894c-4795-8b42-71d13840561c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to perform a semantic search using vector embeddings\n",
    "def retrieve_documents_with_embeddings(query, top_k=5):\n",
    "    # Generate the embedding for the query using your embedding function\n",
    "    query_embedding = vector_db.embedding_function.embed_query(query)\n",
    "    \n",
    "    # Ensure the embedding is in the correct format (e.g., a list of floats)\n",
    "    query_embedding = np.array(query_embedding).tolist()\n",
    "\n",
    "    # Perform a knn search in OpenSearch\n",
    "    search_results = vector_db.client.search(\n",
    "        index=vector_db.index_name,\n",
    "        body={\n",
    "            \"size\": top_k,\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"vector_field\": {\n",
    "                        \"vector\": query_embedding,\n",
    "                        \"k\": top_k\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    documents_with_embeddings = []\n",
    "    for hit in search_results['hits']['hits']:\n",
    "        doc_content = hit['_source']['text']  # Adjust to the correct field name for document text\n",
    "        embedding = hit['_source'].get('vector_field')  # Retrieve the embedding if needed\n",
    "        documents_with_embeddings.append((doc_content, embedding))\n",
    "\n",
    "    return documents_with_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f7287-c0a8-4e7d-ae09-9b475b512e38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Validate that embeddings are getting generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd1da25f-21d7-47d8-a710-b40add83e883",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 documents and their embeddings for the query: \"can you summarize what transformers do?\"\n",
      "\n",
      "Document 1:\n",
      "\n",
      "Content: computer vision and \n",
      "natural language processing tasks, respectively. Breakthroughs like AlexNet in 2012 demonstrated\n",
      "the potential of deep \n",
      "learning in image recognition, while models like GPT-3 and BERT showcased its power in\n",
      "understanding and generating \n",
      "human language.\n",
      "The last decade has seen AI/ML permeate nearly every aspect of modern life, from healthcare and\n",
      "finance to entertainment \n",
      "and autonomous systems. Technologies like facial recognition, recommendation engines, and\n",
      "\n",
      "Embedding: [0.0033366407733410597, -0.09587888419628143, 0.013144778087735176, 0.000498955138027668, -0.0023298643063753843, 0.03460882976651192, 0.013671289198100567, -0.044045694172382355, 0.017882492393255234, -0.03096061758697033, 0.0017778659239411354, 0.03852275013923645, -0.046889711171388626, -0.009664032608270645, 0.00836594682186842, 0.051842328161001205, 0.02841189317405224, 0.05635787546634674, 0.0036378002259880304, -0.05062475427985191, 0.013524573296308517, 0.07404863834381104, 0.05556219443678856, -0.05473781377077103, -0.009280341677367687, -0.020769337192177773, -0.053682517260313034, 0.0012014120584353805, 0.028301039710640907, -0.03312991186976433, -0.000646983680780977, -0.0034042801707983017, 0.07062766700983047, 0.044645849615335464, -0.05180385336279869, 0.0220224317163229, -0.014604760333895683, -0.09506307542324066, 0.019573166966438293, -0.040682677179574966, -0.051859546452760696, -0.06701498478651047, -0.009834022261202335, 0.0037485789507627487, 0.10264534503221512, 0.0630333423614502, -0.018707316368818283, -0.003803638741374016, -0.050911881029605865, -0.002075953409075737, -0.07051392644643784, -0.09797093272209167, -0.01035061851143837, 0.045573070645332336, 0.001946194446645677, -0.05948694422841072, -0.032689549028873444, 0.06038445979356766, 0.056196749210357666, -0.018464015796780586, -0.022893613204360008, 0.003243264276534319, 0.011817170307040215, 0.01186415646225214, -0.004730497021228075, 0.00084082962712273, -0.0011181702138856053, -0.00916840136051178, 0.05056694895029068, -0.10282701998949051, -0.005049224942922592, 0.02350836619734764, -0.016858430579304695, 0.07295399159193039, -0.09643397480249405, 0.122663713991642, 0.1413087546825409, -0.10982069373130798, 0.05283605307340622, -0.05458768457174301, 0.039228420704603195, 0.02699122577905655, 0.06598705798387527, -0.016191391274333, -0.004837781190872192, -0.040800344198942184, -0.01635563001036644, -0.013694901019334793, -0.050170544534921646, -0.018749075010418892, -0.07837936282157898, 0.022474266588687897, 0.02200339362025261, -0.007087094243615866, 0.08042788505554199, 0.05992276594042778, -0.06479161977767944, -0.06011766567826271, 0.021249402314424515, 0.09881305694580078, -0.07721450179815292, 0.057363249361515045, 0.023377355188131332, -0.07168065011501312, 0.033666569739580154, 0.07386000454425812, 0.02495424635708332, -0.06116068735718727, 0.009943158365786076, -0.018883490934967995, -0.07095954567193985, 0.012626255862414837, -0.018161553889513016, -0.03860265389084816, 0.06895345449447632, -0.0832674577832222, -0.03603624179959297, -0.004878286737948656, -0.007381091360002756, 0.07057702541351318, -0.06889153271913528, -0.014861020259559155, -0.018082303926348686, 0.01089261844754219, -0.01034144964069128, -0.016775505617260933, -0.09408204257488251, 0.04070628434419632, 0.06677497178316116, 0.06706944853067398, 0.05532031133770943, 0.028350673615932465, 0.005750924814492464, -0.029765894636511803, 0.046297624707221985, 0.07059679925441742, 0.03096449188888073, -0.061417825520038605, 0.03678346425294876, 0.03296349197626114, -0.08174064755439758, 0.15878815948963165, 0.05981201305985451, -0.03565427288413048, -0.01038383599370718, 0.08160535246133804, -0.017480868846178055, -0.02191946469247341, 0.05207464471459389, -0.06440608948469162, 0.04603215679526329, -0.0657341331243515, 0.044404949992895126, 0.01404009759426117, 0.06466639041900635, -0.13155576586723328, 0.14909584820270538, -0.03094123676419258, -0.09913850575685501, 0.05254487320780754, -0.003547098720446229, 0.01598619669675827, -0.02393707074224949, 0.003913514316082001, 0.036713022738695145, -0.06774178147315979, 0.06438799202442169, 0.020447764545679092, 0.025092536583542824, 0.06142880395054817, 0.021034693345427513, -0.017291465774178505, -0.014154217205941677, 0.02252902463078499, 0.010540210641920567, -0.010693280957639217, -0.05101587995886803, 0.00671476311981678, 0.03994438797235489, -0.03300773724913597, -0.07903828471899033, -0.02424902841448784, 0.06204001232981682, -0.035189438611269, -0.04159845411777496, 0.02627541311085224, 0.016044870018959045, 0.02805376425385475, -0.048713319003582, -0.06052668020129204, 0.028539083898067474, 0.04099701717495918, -0.007328741252422333, 0.021427633240818977, 0.009223081171512604, -0.037711143493652344, -0.02558330073952675, 0.026062479242682457, -0.02348160743713379, 0.017760321497917175, -0.0857710987329483, -0.044864263385534286, -0.027889467775821686, -0.02527119778096676, -0.05688554793596268, -0.13492949306964874, -0.01989918388426304, 0.08279113471508026, -0.04046515002846718, -0.01882130280137062, -0.004043342545628548, -0.03482404723763466, 0.05319218710064888, 0.04387300834059715, 0.05097723752260208, -0.06719540059566498, -0.013056114315986633, -0.052414026111364365, -0.06196005269885063, -0.004114809446036816, -0.10539563000202179, 0.08221311867237091, -0.10310808569192886, 6.776777829736274e-33, -0.05294550210237503, 0.06495977938175201, -0.056711405515670776, 0.08646833896636963, 0.013274084776639938, -0.07611469179391861, 0.039234135299921036, 0.07564632594585419, -0.028586916625499725, 0.06443260610103607, 0.030589863657951355, -0.054469987750053406, -0.01780352182686329, -0.05874641239643097, 0.0023926293943077326, -0.06568358838558197, -0.014651980251073837, -0.0037109379190951586, 0.023630376905202866, -0.0030293362215161324, 0.05765558034181595, 0.06731089949607849, -0.09928657114505768, 0.010234490968286991, -0.002517194487154484, 0.06606408953666687, -0.1215861588716507, 0.025138402357697487, -0.009353909641504288, 0.01319494005292654, -0.02058161422610283, 0.03712081536650658, -0.0009029994835145772, 0.12021631002426147, 0.016573365777730942, 0.04721316695213318, 0.057906556874513626, -0.08067554980516434, 0.01965062879025936, 0.019941283389925957, 0.06103318929672241, 0.034391578286886215, -0.0642411932349205, 0.03734912723302841, -0.05595175921916962, 0.03494810312986374, -0.048983149230480194, -0.049119386821985245, 0.034221988171339035, -0.009854533709585667, 0.020161034539341927, -0.010570350103080273, -0.007233853917568922, -0.05313505604863167, -0.03858764469623566, 0.053199514746665955, -0.017244404181838036, -0.052219633013010025, -0.0254568699747324, 0.07301000505685806, -0.03246819227933884, -0.046968985348939896, 0.030795825645327568, -0.005773133132606745, -0.10820285975933075, -0.0037731819320470095, -0.04896680265665054, 0.07577528059482574, -0.010208475403487682, -0.024763520807027817, 0.07077641040086746, 0.0026474844198673964, 0.027241483330726624, -0.02113979309797287, -0.0352240651845932, 0.04402521252632141, -0.0008714690338820219, -0.028066856786608696, -0.07738081365823746, -0.04253441095352173, 0.023271918296813965, -0.10109709948301315, 0.10272239148616791, 0.036610256880521774, 0.026404015719890594, 0.02994306944310665, -0.007742903660982847, -0.048289909958839417, -0.08531417697668076, 0.010159474797546864, 0.01902848295867443, 0.02610231563448906, -0.046079039573669434, 0.026344124227762222, -0.048592403531074524, 5.450495177820732e-32, 0.006942681968212128, 0.07613922655582428, -0.02130814641714096, -0.01735508069396019, 0.022010186687111855, 0.029471321031451225, 0.020954828709363937, 0.11269661784172058, -0.006457104813307524, -0.012237472459673882, 0.06297227740287781, 0.05051760375499725, -0.026318080723285675, 0.012321666814386845, 0.030023686587810516, 0.018522711470723152, 0.01930629462003708, 0.06611058861017227, 0.019229650497436523, -0.06459084898233414, 0.08050836622714996, 0.0484464168548584, -0.020753039047122, -0.020584959536790848, 0.0159757137298584, -0.09337761253118515, -0.03913210704922676, 0.09557274729013443, -0.045693423599004745, -0.02054283767938614, -0.0112501485273242, 0.0347442701458931, -0.021137524396181107, 0.00396719528362155, 0.01331629604101181, 0.017931560054421425, -0.012656934559345245, -0.030721552670001984, -0.04311411455273628, -0.020201576873660088, 0.008521206676959991, 0.03497287258505821, -0.0353541299700737, -0.041706301271915436, 0.0405840240418911, 0.057504381984472275, 0.027066560462117195, -0.12934790551662445, 0.000842678127810359, -0.036499038338661194, -0.032885003834962845, 0.038013990968465805, 0.07035107165575027, 0.016799533739686012, 0.01879953406751156, 0.06859082728624344, 0.05253617838025093, -0.022227603942155838, -0.09110265970230103, 0.155953511595726, -0.043970704078674316, -0.008089193142950535, 0.02990397810935974, -0.07201553881168365]\n",
      "\n",
      "\n",
      "\n",
      "Document 2:\n",
      "\n",
      "Content: computer vision and \n",
      "natural language processing tasks, respectively. Breakthroughs like AlexNet in 2012 demonstrated\n",
      "the potential of deep \n",
      "learning in image recognition, while models like GPT-3 and BERT showcased its power in\n",
      "understanding and generating \n",
      "human language.\n",
      "The last decade has seen AI/ML permeate nearly every aspect of modern life, from healthcare and\n",
      "finance to entertainment \n",
      "and autonomous systems. Technologies like facial recognition, recommendation engines, and\n",
      "\n",
      "Embedding: [0.0033366407733410597, -0.09587888419628143, 0.013144778087735176, 0.000498955138027668, -0.0023298643063753843, 0.03460882976651192, 0.013671289198100567, -0.044045694172382355, 0.017882492393255234, -0.03096061758697033, 0.0017778659239411354, 0.03852275013923645, -0.046889711171388626, -0.009664032608270645, 0.00836594682186842, 0.051842328161001205, 0.02841189317405224, 0.05635787546634674, 0.0036378002259880304, -0.05062475427985191, 0.013524573296308517, 0.07404863834381104, 0.05556219443678856, -0.05473781377077103, -0.009280341677367687, -0.020769337192177773, -0.053682517260313034, 0.0012014120584353805, 0.028301039710640907, -0.03312991186976433, -0.000646983680780977, -0.0034042801707983017, 0.07062766700983047, 0.044645849615335464, -0.05180385336279869, 0.0220224317163229, -0.014604760333895683, -0.09506307542324066, 0.019573166966438293, -0.040682677179574966, -0.051859546452760696, -0.06701498478651047, -0.009834022261202335, 0.0037485789507627487, 0.10264534503221512, 0.0630333423614502, -0.018707316368818283, -0.003803638741374016, -0.050911881029605865, -0.002075953409075737, -0.07051392644643784, -0.09797093272209167, -0.01035061851143837, 0.045573070645332336, 0.001946194446645677, -0.05948694422841072, -0.032689549028873444, 0.06038445979356766, 0.056196749210357666, -0.018464015796780586, -0.022893613204360008, 0.003243264276534319, 0.011817170307040215, 0.01186415646225214, -0.004730497021228075, 0.00084082962712273, -0.0011181702138856053, -0.00916840136051178, 0.05056694895029068, -0.10282701998949051, -0.005049224942922592, 0.02350836619734764, -0.016858430579304695, 0.07295399159193039, -0.09643397480249405, 0.122663713991642, 0.1413087546825409, -0.10982069373130798, 0.05283605307340622, -0.05458768457174301, 0.039228420704603195, 0.02699122577905655, 0.06598705798387527, -0.016191391274333, -0.004837781190872192, -0.040800344198942184, -0.01635563001036644, -0.013694901019334793, -0.050170544534921646, -0.018749075010418892, -0.07837936282157898, 0.022474266588687897, 0.02200339362025261, -0.007087094243615866, 0.08042788505554199, 0.05992276594042778, -0.06479161977767944, -0.06011766567826271, 0.021249402314424515, 0.09881305694580078, -0.07721450179815292, 0.057363249361515045, 0.023377355188131332, -0.07168065011501312, 0.033666569739580154, 0.07386000454425812, 0.02495424635708332, -0.06116068735718727, 0.009943158365786076, -0.018883490934967995, -0.07095954567193985, 0.012626255862414837, -0.018161553889513016, -0.03860265389084816, 0.06895345449447632, -0.0832674577832222, -0.03603624179959297, -0.004878286737948656, -0.007381091360002756, 0.07057702541351318, -0.06889153271913528, -0.014861020259559155, -0.018082303926348686, 0.01089261844754219, -0.01034144964069128, -0.016775505617260933, -0.09408204257488251, 0.04070628434419632, 0.06677497178316116, 0.06706944853067398, 0.05532031133770943, 0.028350673615932465, 0.005750924814492464, -0.029765894636511803, 0.046297624707221985, 0.07059679925441742, 0.03096449188888073, -0.061417825520038605, 0.03678346425294876, 0.03296349197626114, -0.08174064755439758, 0.15878815948963165, 0.05981201305985451, -0.03565427288413048, -0.01038383599370718, 0.08160535246133804, -0.017480868846178055, -0.02191946469247341, 0.05207464471459389, -0.06440608948469162, 0.04603215679526329, -0.0657341331243515, 0.044404949992895126, 0.01404009759426117, 0.06466639041900635, -0.13155576586723328, 0.14909584820270538, -0.03094123676419258, -0.09913850575685501, 0.05254487320780754, -0.003547098720446229, 0.01598619669675827, -0.02393707074224949, 0.003913514316082001, 0.036713022738695145, -0.06774178147315979, 0.06438799202442169, 0.020447764545679092, 0.025092536583542824, 0.06142880395054817, 0.021034693345427513, -0.017291465774178505, -0.014154217205941677, 0.02252902463078499, 0.010540210641920567, -0.010693280957639217, -0.05101587995886803, 0.00671476311981678, 0.03994438797235489, -0.03300773724913597, -0.07903828471899033, -0.02424902841448784, 0.06204001232981682, -0.035189438611269, -0.04159845411777496, 0.02627541311085224, 0.016044870018959045, 0.02805376425385475, -0.048713319003582, -0.06052668020129204, 0.028539083898067474, 0.04099701717495918, -0.007328741252422333, 0.021427633240818977, 0.009223081171512604, -0.037711143493652344, -0.02558330073952675, 0.026062479242682457, -0.02348160743713379, 0.017760321497917175, -0.0857710987329483, -0.044864263385534286, -0.027889467775821686, -0.02527119778096676, -0.05688554793596268, -0.13492949306964874, -0.01989918388426304, 0.08279113471508026, -0.04046515002846718, -0.01882130280137062, -0.004043342545628548, -0.03482404723763466, 0.05319218710064888, 0.04387300834059715, 0.05097723752260208, -0.06719540059566498, -0.013056114315986633, -0.052414026111364365, -0.06196005269885063, -0.004114809446036816, -0.10539563000202179, 0.08221311867237091, -0.10310808569192886, 6.776777829736274e-33, -0.05294550210237503, 0.06495977938175201, -0.056711405515670776, 0.08646833896636963, 0.013274084776639938, -0.07611469179391861, 0.039234135299921036, 0.07564632594585419, -0.028586916625499725, 0.06443260610103607, 0.030589863657951355, -0.054469987750053406, -0.01780352182686329, -0.05874641239643097, 0.0023926293943077326, -0.06568358838558197, -0.014651980251073837, -0.0037109379190951586, 0.023630376905202866, -0.0030293362215161324, 0.05765558034181595, 0.06731089949607849, -0.09928657114505768, 0.010234490968286991, -0.002517194487154484, 0.06606408953666687, -0.1215861588716507, 0.025138402357697487, -0.009353909641504288, 0.01319494005292654, -0.02058161422610283, 0.03712081536650658, -0.0009029994835145772, 0.12021631002426147, 0.016573365777730942, 0.04721316695213318, 0.057906556874513626, -0.08067554980516434, 0.01965062879025936, 0.019941283389925957, 0.06103318929672241, 0.034391578286886215, -0.0642411932349205, 0.03734912723302841, -0.05595175921916962, 0.03494810312986374, -0.048983149230480194, -0.049119386821985245, 0.034221988171339035, -0.009854533709585667, 0.020161034539341927, -0.010570350103080273, -0.007233853917568922, -0.05313505604863167, -0.03858764469623566, 0.053199514746665955, -0.017244404181838036, -0.052219633013010025, -0.0254568699747324, 0.07301000505685806, -0.03246819227933884, -0.046968985348939896, 0.030795825645327568, -0.005773133132606745, -0.10820285975933075, -0.0037731819320470095, -0.04896680265665054, 0.07577528059482574, -0.010208475403487682, -0.024763520807027817, 0.07077641040086746, 0.0026474844198673964, 0.027241483330726624, -0.02113979309797287, -0.0352240651845932, 0.04402521252632141, -0.0008714690338820219, -0.028066856786608696, -0.07738081365823746, -0.04253441095352173, 0.023271918296813965, -0.10109709948301315, 0.10272239148616791, 0.036610256880521774, 0.026404015719890594, 0.02994306944310665, -0.007742903660982847, -0.048289909958839417, -0.08531417697668076, 0.010159474797546864, 0.01902848295867443, 0.02610231563448906, -0.046079039573669434, 0.026344124227762222, -0.048592403531074524, 5.450495177820732e-32, 0.006942681968212128, 0.07613922655582428, -0.02130814641714096, -0.01735508069396019, 0.022010186687111855, 0.029471321031451225, 0.020954828709363937, 0.11269661784172058, -0.006457104813307524, -0.012237472459673882, 0.06297227740287781, 0.05051760375499725, -0.026318080723285675, 0.012321666814386845, 0.030023686587810516, 0.018522711470723152, 0.01930629462003708, 0.06611058861017227, 0.019229650497436523, -0.06459084898233414, 0.08050836622714996, 0.0484464168548584, -0.020753039047122, -0.020584959536790848, 0.0159757137298584, -0.09337761253118515, -0.03913210704922676, 0.09557274729013443, -0.045693423599004745, -0.02054283767938614, -0.0112501485273242, 0.0347442701458931, -0.021137524396181107, 0.00396719528362155, 0.01331629604101181, 0.017931560054421425, -0.012656934559345245, -0.030721552670001984, -0.04311411455273628, -0.020201576873660088, 0.008521206676959991, 0.03497287258505821, -0.0353541299700737, -0.041706301271915436, 0.0405840240418911, 0.057504381984472275, 0.027066560462117195, -0.12934790551662445, 0.000842678127810359, -0.036499038338661194, -0.032885003834962845, 0.038013990968465805, 0.07035107165575027, 0.016799533739686012, 0.01879953406751156, 0.06859082728624344, 0.05253617838025093, -0.022227603942155838, -0.09110265970230103, 0.155953511595726, -0.043970704078674316, -0.008089193142950535, 0.02990397810935974, -0.07201553881168365]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"can you summarize what transformers do?\"\n",
    "documents_with_embeddings = retrieve_documents_with_embeddings(query,2)\n",
    "\n",
    "# Print the documents and their embeddings\n",
    "print(f\"Top {len(documents_with_embeddings)} documents and their embeddings for the query: \\\"{query}\\\"\")\n",
    "for idx, (content, embedding) in enumerate(documents_with_embeddings):\n",
    "    print(f\"\\nDocument {idx + 1}:\\n\")\n",
    "    print(f\"Content: {content}\\n\")\n",
    "    print(f\"Embedding: {embedding}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62296f96-ea78-4eda-936d-72c15c381d59",
   "metadata": {
    "tags": []
   },
   "source": [
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; validate semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e8ca4f8-8c74-4da3-992c-fbce90a248bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 results for the query: \"what period in history is considered the AI winter and why?\"\n",
      "\n",
      "Result 1:\n",
      "Document: their ability to handle complexity and ambiguity.\n",
      "The 1970s and 1980s brought about the first \"AI winter,\" a period characterized by reduced funding\n",
      "and enthusiasm for \n",
      "AI research. The limitations of symbolic AI became apparent as researchers struggled to scale these\n",
      "systems to handle \n",
      "real-world problems. During this time, expert systems, which encoded domain-specific knowledge,\n",
      "gained traction but \n",
      "eventually faced scalability issues.\n",
      "\n",
      "\n",
      "Result 2:\n",
      "Document: their ability to handle complexity and ambiguity.\n",
      "The 1970s and 1980s brought about the first \"AI winter,\" a period characterized by reduced funding\n",
      "and enthusiasm for \n",
      "AI research. The limitations of symbolic AI became apparent as researchers struggled to scale these\n",
      "systems to handle \n",
      "real-world problems. During this time, expert systems, which encoded domain-specific knowledge,\n",
      "gained traction but \n",
      "eventually faced scalability issues.\n",
      "\n",
      "\n",
      "Result 3:\n",
      "Document: their ability to handle complexity and ambiguity.\n",
      "The 1970s and 1980s brought about the first \"AI winter,\" a period characterized by reduced funding\n",
      "and enthusiasm for \n",
      "AI research. The limitations of symbolic AI became apparent as researchers struggled to scale these\n",
      "systems to handle \n",
      "real-world problems. During this time, expert systems, which encoded domain-specific knowledge,\n",
      "gained traction but \n",
      "eventually faced scalability issues.\n",
      "\n",
      "\n",
      "Result 4:\n",
      "Document: groundbreaking, were limited in \n",
      "their ability to handle complexity and ambiguity.\n",
      "The 1970s and 1980s brought about the first \"AI winter,\" a period characterized by reduced funding\n",
      "and enthusiasm for \n",
      "AI research. The limitations of symbolic AI became apparent as researchers struggled to scale these\n",
      "systems to handle \n",
      "real-world problems. During this time, expert systems, which encoded domain-specific knowledge,\n",
      "gained traction but \n",
      "eventually faced scalability issues.\n",
      "\n",
      "\n",
      "Result 5:\n",
      "Document: Researchers focused \n",
      "on rule-based systems and symbolic reasoning, which led to the development of early programs like\n",
      "ELIZA, a natural \n",
      "language processing program, and the General Problem Solver. These systems, while\n",
      "groundbreaking, were limited in \n",
      "their ability to handle complexity and ambiguity.\n",
      "The 1970s and 1980s brought about the first \"AI winter,\" a period characterized by reduced funding\n",
      "and enthusiasm for\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Semantic Search Test Function\n",
    "def semantic_search_test(query, top_k=5):\n",
    "    # Perform a semantic search\n",
    "    search_results = vector_db.similarity_search(query, k=top_k)\n",
    "    \n",
    "    # Display the top-k retrieved documents\n",
    "    print(f\"Top {top_k} results for the query: \\\"{query}\\\"\")\n",
    "    for idx, result in enumerate(search_results):\n",
    "        print(f\"\\nResult {idx + 1}:\")\n",
    "        print(f\"Document: {result.page_content}\\n\")\n",
    "\n",
    "# Run a semantic search test\n",
    "semantic_search_test(\"what period in history is considered the AI winter and why?\", top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b842e2-024f-49e4-b723-dd0c252395a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Retrieve topK documents with similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdc479b4-cb2d-4a76-89aa-370744f64972",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.53234446\n",
      "Document: their ability to handle complexity and ambiguity.\n",
      "The 1970s and 1980s brought about the first \"AI winter,\" a period characterized by reduced funding\n",
      "and enthusiasm for \n",
      "AI research. The limitations of symbolic AI became apparent as researchers struggled to scale these\n",
      "systems to handle \n",
      "real-world problems. During this time, expert systems, which encoded domain-specific knowledge,\n",
      "gained traction but \n",
      "eventually faced scalability issues.\n",
      "\n",
      "Score: 0.53234446\n",
      "Document: their ability to handle complexity and ambiguity.\n",
      "The 1970s and 1980s brought about the first \"AI winter,\" a period characterized by reduced funding\n",
      "and enthusiasm for \n",
      "AI research. The limitations of symbolic AI became apparent as researchers struggled to scale these\n",
      "systems to handle \n",
      "real-world problems. During this time, expert systems, which encoded domain-specific knowledge,\n",
      "gained traction but \n",
      "eventually faced scalability issues.\n",
      "\n",
      "Score: 0.53234446\n",
      "Document: their ability to handle complexity and ambiguity.\n",
      "The 1970s and 1980s brought about the first \"AI winter,\" a period characterized by reduced funding\n",
      "and enthusiasm for \n",
      "AI research. The limitations of symbolic AI became apparent as researchers struggled to scale these\n",
      "systems to handle \n",
      "real-world problems. During this time, expert systems, which encoded domain-specific knowledge,\n",
      "gained traction but \n",
      "eventually faced scalability issues.\n",
      "\n",
      "Score: 0.5307652\n",
      "Document: groundbreaking, were limited in \n",
      "their ability to handle complexity and ambiguity.\n",
      "The 1970s and 1980s brought about the first \"AI winter,\" a period characterized by reduced funding\n",
      "and enthusiasm for \n",
      "AI research. The limitations of symbolic AI became apparent as researchers struggled to scale these\n",
      "systems to handle \n",
      "real-world problems. During this time, expert systems, which encoded domain-specific knowledge,\n",
      "gained traction but \n",
      "eventually faced scalability issues.\n",
      "\n",
      "Score: 0.52448976\n",
      "Document: Researchers focused \n",
      "on rule-based systems and symbolic reasoning, which led to the development of early programs like\n",
      "ELIZA, a natural \n",
      "language processing program, and the General Problem Solver. These systems, while\n",
      "groundbreaking, were limited in \n",
      "their ability to handle complexity and ambiguity.\n",
      "The 1970s and 1980s brought about the first \"AI winter,\" a period characterized by reduced funding\n",
      "and enthusiasm for\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate topK documents with scores\n",
    "query = \"what period in history is considered the AI winter and why?\"\n",
    "query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "# Perform a similarity search using the query embedding and retrieve scores\n",
    "search_results = vector_db.similarity_search_with_score_by_vector(query_embedding, k=5)\n",
    "\n",
    "# Iterate over the search results and print the text along with the scores\n",
    "for document, score in search_results:\n",
    "    print(f\"Score: {score}\")\n",
    "    print(f\"Document: {document.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d1fd72-7bf4-43d9-ba38-85273ef6dfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_p310_any_x86_64_v1]",
   "language": "python",
   "name": "conda-env-python_p310_any_x86_64_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
